{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoFIS code experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from main.autoFIS.autoFIS.fuzzification import Fuzzification\n",
    "from main.autoFIS.autoFIS.formulation import Formulation\n",
    "from main.autoFIS.autoFIS.association import Association\n",
    "from main.autoFIS.autoFIS.aggregation import Aggregation\n",
    "from main.autoFIS.autoFIS.decision import Decision\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing benchmark dataset Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df_iris = pd.DataFrame(iris['data'])\n",
    "df_iris['target'] = iris['target']\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are set by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_attributes = [False, False, False, False]\n",
    "triangle_format = 'normal'  # \"tukey\", \"normal\"\n",
    "n_fuzzy_sets = 5  # 3, 5, 7\n",
    "enable_negation = False\n",
    "\n",
    "# -------------------------\n",
    "# Formulation parameters\n",
    "# -------------------------\n",
    "premise_max_size = 2\n",
    "t_norm = 'prod'  # \"min\", \"prod\"\n",
    "\n",
    "# Area filter parameters:\n",
    "criteria_support = \"cardinalidade_relativa\"  # \"cardinalidade_relativa\", \"frequencia_relativa\"\n",
    "area_threshold = 0.05\n",
    "\n",
    "enable_pcd_premises_base = True\n",
    "enable_pcd_premises_derived = True\n",
    "\n",
    "# Overlapping filter parameters:\n",
    "enable_similarity_premises_bases = True\n",
    "enable_similarity_premises_derived = True\n",
    "threshold_similarity = 0.95\n",
    "\n",
    "association_method = \"MQR\"  # \"MQR\", \"PMQR\", \"CD\", \"PCD\", \"freq_max\"\n",
    "\n",
    "aggregation_method = \"MQR\"  # \"MQR\", \"PMQR\", \"CD\", \"PCD\", \"freq_max\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzification_params = {\n",
    "    'triangle_format' : 'normal',\n",
    "    'n_fuzzy_sets': n_fuzzy_sets,\n",
    "    'enable_negation': enable_negation\n",
    "}\n",
    "\n",
    "fuzzifier = Fuzzification(**fuzzification_params)\n",
    "fuzzifier.fit(X_train,is_categorical = categorical_attributes)\n",
    "# TODO: put fuzzy_premises and num_fuzzy_premises to be calculated INSIDE the formulation step. Not in the fuzzification step. this is wrong.\n",
    "uX,fuzzy_premises,num_fuzzy_premises = fuzzifier.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor this part when building the AutoFIS class\n",
    "y_categories = np.unique(y_train)\n",
    "y_encoder = OneHotEncoder(categories = [y_categories], drop='if_binary')\n",
    "y_train_one_hot = y_encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "number_classes = y_train_one_hot.shape[1]\n",
    "percentage_of_classes = y_train_one_hot.sum(axis = 0) / y_train_one_hot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done with Formulation...\nDepth level 1: 18\nDepth level 2: 31\n"
    }
   ],
   "source": [
    "formulation_params = {\n",
    "\n",
    "    'antecedents_by_attribute': fuzzy_premises,\n",
    "    'num_of_antecedents_by_attribute': num_fuzzy_premises,\n",
    "    \n",
    "    'attribute_is_binary': fuzzifier.fuzzy_params['is_binary'],\n",
    "    'ux': uX, \n",
    "    'target_class': y_train_one_hot,\n",
    "    'enable_negation': enable_negation,\n",
    "    't_norm':t_norm,\n",
    "    'premise_max_size' : premise_max_size,\n",
    "    'criteria_support' : criteria_support,  # 'cardinalidade relativa', 'frequencia relativa'\n",
    "    'threshold_support' : area_threshold,  # tolerancia da area\n",
    "    'enable_similarity_premises_bases' : enable_similarity_premises_bases,\n",
    "    'enable_similarity_premises_derived' : enable_similarity_premises_derived,\n",
    "    'threshold_similarity' : threshold_similarity,\n",
    "    'enable_pcd_premises_base' : enable_pcd_premises_base,\n",
    "    'enable_pcd_premises_derived' : enable_pcd_premises_derived\n",
    "}\n",
    "\n",
    "formulator = Formulation(**formulation_params)\n",
    "tree = formulator.generate_premises()\n",
    "\n",
    "#TODO: Colocar essas mensagens dentro de alguma etapa de validação de premissas.\n",
    "status = [False if not i[0] else True for i in tree] # checa se tem alguma ordem de premisas vazia\n",
    "sum_status = sum(status)\n",
    "if sum_status != len(tree): \n",
    "    if sum_status == 0:\n",
    "        raise ValueError(\"Error in Formulation Module. Any premise survived. \"\n",
    "                            \"Sorry, you can not continue in the next stage.\"\n",
    "                            \"\\nTry to change the configuration\")\n",
    "    else:\n",
    "        # TODO: Consertar isso. Acho que ele filtra só as ordens de premissas que estão preenchidas\n",
    "        arb = [i for i in tree if i[0]]\n",
    "        tree, arb = arb, tree\n",
    "\n",
    "print('Done with Formulation...')\n",
    "for i,values in enumerate(tree):\n",
    "    print('Depth level ' + str(i + 1) + ': ' + str(tree[i][1].shape[1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done with Association...\n\nRules per class:\nclass  0 :  [(1,), (10,), (15,), (10, 15)]\nclass  1 :  [(12,), (17,), (12, 17)]\nclass  2 :  [(13,), (18,), (19,), (13, 18), (13, 19)]\n"
    }
   ],
   "source": [
    "#TODO: Se sobrar tempo, fazer class polymorphismo nos métodos de agregação\n",
    "\n",
    "associator = Association(tree, y_train_one_hot)\n",
    "association_rules = associator.build_association_rules(association_method)\n",
    "\n",
    "#TODO: Colocar essas mensagens dentro de alguma etapa de validação de premissas.\n",
    "status = [0 if not i[0] else 1 for i in association_rules]\n",
    "if sum(status) != number_classes:\n",
    "    raise ValueError(\"Error in Association Module. Some classes did not get premises. \"\n",
    "                     \"\\nTry to change the configuration\")\n",
    "print('Done with Association...')\n",
    "print('')\n",
    "print('Rules per class:')\n",
    "\n",
    "for index,i in enumerate(association_rules):\n",
    "    print('class ', index, ': ', i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done with Aggregation...\n\nPremises of Class 0: [(1,), (10,), (15,)]\nweights: [[0.02410548 0.62684905 0.34904547]]\n\nPremises of Class 1: [(12,), (17,)]\nweights: [[0.40570462 0.5942954 ]]\n\nPremises of Class 2: [(13,), (18,), (19,)]\nweights: [[0.44368515 0.44333386 0.11298105]]\n\n"
    }
   ],
   "source": [
    "#TODO: Se sobrar tempo, fazer class polymorphismo nos métodos de agregação\n",
    "#TODO: Se sobrar tempo [2], remover import de auxfunc e deixar tudo dentro de uma classe só. A menos q esteja sendo usado em outro lugar a mesma função.\n",
    "aggregator = Aggregation(association_rules)\n",
    "aggregation_rules,estimation_classes  = aggregator.aggregate_rules(y_train_one_hot, aggregation_method)\n",
    "\n",
    "#TODO: Colocar essas mensagens dentro de alguma etapa de validação de premissas.\n",
    "\n",
    "status = [0 if not i[0] else 1 for i in aggregation_rules]\n",
    "if sum(status) != number_classes:\n",
    "    raise ValueError(\"Error in Aggregation Module. Some classes did not get premises. \"\n",
    "                        \"Sorry, you can not continue in the next stage.\"\n",
    "                        \"\\nTry to change the configuration\")\n",
    "print('Done with Aggregation...')\n",
    "print('')\n",
    "\n",
    "final_premises_classes = []\n",
    "for index,i in enumerate(aggregation_rules):\n",
    "    print(\"Premises of Class \" + str(index) + \": \" + str(i[0]))\n",
    "    final_premises_classes.append(i[0])\n",
    "    print(\"weights: \" + str(i[1].T))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_maker = Decision(aggregation_rules, percentage_of_classes)\n",
    "y_train_prediction = decision_maker.predict(uX,t_norm)\n",
    "y_train_prediction = y_encoder.inverse_transform(y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train: \n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9619047619047619"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "print('train: ')\n",
    "accuracy_score(y_train_prediction, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ux_test,_,_ = fuzzifier.transform(X_test)\n",
    "# y_test_one_hot = y_encoder.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "y_test_pred = decision_maker.predict(ux_test,t_norm)\n",
    "y_test_pred = y_encoder.inverse_transform(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "test: \n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9777777777777777"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "print('test: ')\n",
    "accuracy_score(y_test_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('puc': venv)",
   "language": "python",
   "name": "python37764bitpucvenv3c8e04841bf343089962c3369eba30a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}