{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from fuzzyfication import Fuzzification\n",
    "#from tnorm import tnorm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from basicfuzzy import trimf, trapmf\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "    print(len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for t-norm\n",
    "\n",
    "def tnorm_product(values):\n",
    "    return np.prod(values,axis=0)\n",
    "\n",
    "def tnorm_minimum(values):\n",
    "    return values.min(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('series/cluster4.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mat.get('cluster4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filedata = pd.read_csv(\"cluster1.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = filedata.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição de parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definicao de variaveis \n",
    "\n",
    "h_prev = 12\n",
    "lag = 6                  #Actually, lag stands for all inputs for each serie. Example, lag = 2 uses s(t) and s(t-1) to predict s(t+1)\n",
    "diff_series = False\n",
    "\n",
    "#bin_values = 12; #Representação da binarização do tempo.\n",
    "#lag_notused = []\n",
    "\n",
    "num_series = data.shape[1]  #Numero de series do problema, extraído dos dados\n",
    "\n",
    "max_rulesize = 5; #Max numbers of premises rules.\n",
    "min_activation = 0.18 #Minimum activation\n",
    "\n",
    "#####Definicao de funcoes######\n",
    "#detrend_method = ''\n",
    "#bin_method = ''\n",
    "\n",
    "fuzzy_method = 'mfdef_cluster'\n",
    "#Formacao de premissas\n",
    "\n",
    "#form_method = 'form_NonExaustiveSparseBU_v4'\n",
    "#form_param = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if diff_series:\n",
    "    diff_data = data[1:,:] - data[0:data.shape[0]-1,:]\n",
    "\n",
    "    in_sample = diff_data[:diff_data.shape[0]-h_prev,:]\n",
    "    \n",
    "    out_sample = diff_data[diff_data.shape[0]-h_prev:,:]\n",
    "else:\n",
    "    in_sample = data[:data.shape[0]-h_prev,:]\n",
    "    out_sample = data[data.shape[0]-h_prev:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazer detrend method\n",
    "\n",
    "#Definicao do target\n",
    "yt = np.zeros((in_sample.shape[0]-lag-1,num_series),dtype='float')\n",
    "\n",
    "#Todas as entradas defasadas \n",
    "yp = np.zeros((in_sample.shape[0]-lag-1,num_series), dtype='float')\n",
    "yp_lagged = np.zeros((in_sample.shape[0]-lag-1,num_series*lag),dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_series):\n",
    "    yp[:,i] = in_sample[lag:in_sample.shape[0]-1,i]\n",
    "    yt[:,i] = in_sample[lag+1:,i]\n",
    "    for k in range(lag):\n",
    "        yp_lagged[:,i*lag+k] = in_sample[lag-k:in_sample.shape[0]-k-1,i]\n",
    "        #print(i*lag+k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apenas para visualização de dados do problema"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for n in range(yp.shape[1]):\n",
    "    plt.figure()\n",
    "    n, bins, patches = plt.hist(x=yp[:,n], bins='auto', color='#0504aa',\n",
    "                                alpha=0.7, rwidth=0.5)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for n in range(yp.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(0,yp.shape[0],yp.shape[0]),yp[:,n])\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.xlabel('Time (month)')\n",
    "    plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "series = pd.DataFrame(yp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r_window_size = 10\n",
    "\n",
    "for i in range(yp.shape[1]):\n",
    "    for j in range(yp.shape[1]):\n",
    "        if (i > j) or (i == j):\n",
    "            pass\n",
    "        else:\n",
    "            plt.figure()\n",
    "\n",
    "            overall_pearson_r = series.corr().iloc[i,j]\n",
    "            rolling_r = series[i].rolling(window=r_window_size, center=True).corr(series[j])\n",
    "            f,ax=plt.subplots(2,1,figsize=(14,6),sharex=True)\n",
    "            series[i].rolling(window=3,center=True).median().plot(ax=ax[0])\n",
    "            series[j].rolling(window=3,center=True).median().plot(ax=ax[0])\n",
    "\n",
    "            ax[0].set(xlabel='Time (month)',ylabel='Values')\n",
    "            rolling_r.plot(ax=ax[1])\n",
    "            ax[1].set(xlabel='Time',ylabel='Pearson correlation')\n",
    "            plt.suptitle(\"Series {} and {}. Overall Pearson: {}\".format(i,j,np.round(overall_pearson_r,2)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def crosscorr(datax, datay, lag=0, wrap=False):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Shifted data filled with NaNs \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    if wrap:\n",
    "        shiftedy = datay.shift(lag)\n",
    "        shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "        return datax.corr(shiftedy)\n",
    "    else: \n",
    "        return datax.corr(datay.shift(lag))\n",
    "\n",
    "for i in range(yp.shape[1]):\n",
    "    for j in range(yp.shape[1]):\n",
    "        if (i > j) or (i == j):\n",
    "            pass\n",
    "        else:\n",
    "            plt.figure()\n",
    "\n",
    "            d1 = series[i]\n",
    "            d2 = series[j]\n",
    "\n",
    "            lag_max = 5\n",
    "\n",
    "            rs = [crosscorr(d1,d2, lag) for lag in range(-lag_max,lag_max+1)]\n",
    "            offset = np.ceil(len(rs)/2)-np.argmax(rs)\n",
    "            f,ax=plt.subplots(figsize=(14,3))\n",
    "            ax.plot(np.linspace(-lag_max,lag_max,2*lag_max+1),rs)\n",
    "            ax.axvline(np.argmax(rs)-lag_max,color='r',linestyle='--',label='Peak synchrony')\n",
    "            #ax.set(title=f'Offset = {offset} frames\\nS1 leads <> S2 leads',ylim=[.1,.31],xlim=[0,301], xlabel='Offset',ylabel='Pearson r')\n",
    "            ax.set(xlabel='Lag value',ylabel='Cross-correlation',title='Cross-correlation between series {} and {}'.format(i+1,j+1))\n",
    "            plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "serie0 = np.array(series[0]).reshape(-1,1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(serie0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(kmeans.cluster_centers_.sort)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "centers = np.asarray(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "centers.sort(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[a],[b],[c],[d],[e]] = centers.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fuzzyfy = Fuzzification(fuzzy_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lembrete: \n",
    "#axis 0 - Registros da série\n",
    "#axis 1 - Valor de pertinência ao conjunto Fuzzy\n",
    "#axis 2 - Numero de séries\n",
    "\n",
    "first_time = True\n",
    "for n in range(num_series):\n",
    "    \n",
    "    _, mf_params = Fuzzyfy.fuzzify(in_sample[:,n],np.array([]))\n",
    "    mX, _ = Fuzzyfy.fuzzify(yp[:,n],mf_params)\n",
    "    mY, _ = Fuzzyfy.fuzzify(yt[:,n],mf_params)\n",
    "    if first_time:\n",
    "        mX_ = np.ndarray([mX.shape[0],mX.shape[1], num_series])\n",
    "        mY_ = np.ndarray([mY.shape[0],mY.shape[1], num_series])\n",
    "        mf_params_ = np.ndarray([mf_params.shape[0],num_series])\n",
    "        first_time = False\n",
    "    mX_[:,:,n] = mX\n",
    "    mY_[:,:,n] = mY\n",
    "    mf_params_[:,n] = mf_params\n",
    "    #print(mf_params)\n",
    "    #print(mX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mX_lagged_ = np.ndarray([mX_.shape[0],mX_.shape[1],yp_lagged.shape[1]])\n",
    "for i in range(num_series):\n",
    "    mf_params = mf_params_[:,i]\n",
    "    for j in range(lag):\n",
    "        mX, _ = Fuzzyfy.fuzzify(yp_lagged[:,i*lag+j],mf_params)\n",
    "        mX_lagged_[:,:,i*lag+j] = mX\n",
    "        #print(i*lag+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rules are created using t-norms, like \"If x1 is A and x2 is B and x3 is C\"\n",
    "#Each rule will be stored as a list of tuples, whose each tuple corresponds to temporal series Number and fuzzy set\n",
    "#Example: if we have only one rule as \"if s1 is NB\", then the fuzzy rule is stored as (1,0)\n",
    "#This is just for antecedent rules. If we have a complete rule \"If x1 is A and x2 is B and x3 is C then x4 is Aa\",\n",
    "#the last tuple will be always the consequent.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we use cardinality based on mean activation and relative frequency. We are going to use other functions to evaluate\n",
    "\n",
    "def hybrid_func(values,min_act):\n",
    "    values = np.asarray(values)\n",
    "    if np.sum(values) == 0:\n",
    "        return False, 0, 0\n",
    "    else:\n",
    "        mean_activation = np.mean(values[values>0],axis=0)\n",
    "        freq = np.sum(values>0)\n",
    "        freq_rel = freq/len(values)\n",
    "\n",
    "        check_activation = mean_activation*freq_rel\n",
    "        if check_activation > min_act:\n",
    "            activation = True\n",
    "        else:\n",
    "            activation = False\n",
    "        return activation, mean_activation, check_activation\n",
    "    \n",
    "def freq_func(values,min_act):\n",
    "    values = np.asarray(values)\n",
    "    if np.sum(values) == 0:\n",
    "        return False, 0, 0\n",
    "    else:\n",
    "        freq = np.sum(values>0)\n",
    "        freq_rel = freq/len(values)\n",
    "\n",
    "        check_activation = freq_rel\n",
    "        if check_activation > min_act:\n",
    "            activation = True\n",
    "        else:\n",
    "            activation = False\n",
    "        return activation, freq_rel, check_activation\n",
    "\n",
    "def card_func(values,min_act):\n",
    "    values = np.asarray(values)\n",
    "    if np.sum(values) == 0:\n",
    "        return False, 0, 0\n",
    "    else:\n",
    "        mean_activation = np.mean(values[values>0],axis=0)\n",
    "\n",
    "        check_activation = mean_activation\n",
    "        if check_activation > min_act:\n",
    "            activation = True\n",
    "        else:\n",
    "            activation = False\n",
    "        return activation, mean_activation, check_activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check if the antecedent is inside a function\n",
    "\n",
    "def check_if_inside(val,eachRule):\n",
    "    if val in eachRule:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function just to sort antecedent rules in numerical order.\n",
    "\n",
    "def rearranje_rules(rule):\n",
    "    sorted_rule = []\n",
    "    first_rules = np.unique([num_series[0] for num_series in rule])\n",
    "    \n",
    "    for val in first_rules:\n",
    "        arranje_rule = [thisantecedent for thisantecedent in rule if thisantecedent[0] == val]\n",
    "        arranje_rule.sort(key=lambda x: x[1])\n",
    "        \n",
    "        sorted_rule.extend(arranje_rule)\n",
    "        \n",
    "    return sorted_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_rules(val,rules):\n",
    "    for rule in rules:\n",
    "        if val == rule:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rulesize = [0]\n",
    "\n",
    "prem_terms = np.array([])\n",
    "\n",
    "for r in range(0,max_rulesize):\n",
    "    \n",
    "    if r == 0:\n",
    "        rules1 = []        \n",
    "        for i in range(mX_lagged_.shape[2]):\n",
    "            for j in range(mX_lagged_.shape[1]):\n",
    "                #print(mX_lagged_[:,j,i].shape)\n",
    "                activation, mean_activation, freq = card_func(mX_lagged_[:,j,i],min_activation)\n",
    "                #print(mean_activation)\n",
    "                #print(freq)\n",
    "                #print(activation)\n",
    "                if activation is True:\n",
    "                    rules1.append([(i,j)])\n",
    "                    if prem_terms.size == 0:\n",
    "                        prem_terms = mX_lagged_[:,j,i]\n",
    "                    else:\n",
    "                        prem_terms = np.vstack((prem_terms,mX_lagged_[:,j,i]))\n",
    "                    \n",
    "        rules = np.empty(shape=[len(rules1), 1],dtype='object')\n",
    "        rulesize.append(len(rules1))\n",
    "        rules[:,0] = rules1\n",
    "    \n",
    "    else:\n",
    "        lim_sup = rulesize[r]\n",
    "        lim_inf = rulesize[r-1]\n",
    "        new_rules = []           #Reinicia a lista de novas regras a cada layer de regra.\n",
    "        #print(lim_sup,lim_inf)\n",
    "        #Vamos verificar cada regra criada na rodada anterior. Para isso, verificamos o range que a lista de regras está alocada\n",
    "        for rule in range(lim_inf,lim_inf+lim_sup):\n",
    "            \n",
    "            grow_rule = rules[rule,0]\n",
    "            #print(grow_rule)\n",
    "            for i in range(mX_lagged_.shape[2]):\n",
    "                for j in range(mX_lagged_.shape[1]):\n",
    "                    \n",
    "                    \n",
    "                    #Checa se o novo antecedente já está dentro do conjunto de antecedentes da regra\n",
    "                    if check_if_inside((i,j),grow_rule):\n",
    "                        continue\n",
    "                    #Vamos concatenar todas as regras\n",
    "                    count_tnorm = mX_lagged_[:,j,i]\n",
    "                    \n",
    "                    for r_size in grow_rule:               \n",
    "                        count_tnorm = np.vstack((count_tnorm,mX_lagged_[:,r_size[1],r_size[0]]))\n",
    "                        \n",
    "                        #print(count_tnorm.shape)\n",
    "                        #print(count_tnorm[:,1:4])\n",
    "                    tnorm_ = tnorm_product(count_tnorm)\n",
    "                    #print(tnorm_min[1:4])\n",
    "                    activation, mean_activation, freq = card_func(tnorm_,min_activation)\n",
    "\n",
    "                    if activation is True:\n",
    "                        rule_to_append = deepcopy(grow_rule)\n",
    "                        \n",
    "                        rule_to_append.append((i,j))\n",
    "                        #print(rule_to_append)\n",
    "                        #print(mean_activation)\n",
    "                        #print(freq)\n",
    "                        sorted_rule = rearranje_rules(rule_to_append)\n",
    "                        #print('Added {} to base rule'.format(sorted_rule))\n",
    "                        print(sorted_rule) \n",
    "                        if not check_duplicate_rules(sorted_rule, new_rules):\n",
    "                            new_rules.append(sorted_rule)\n",
    "                        else:\n",
    "                            print('Found one')\n",
    "                            \n",
    "                        prem_terms = np.vstack((prem_terms,tnorm_))\n",
    "\n",
    "                        \n",
    "        rulesize.append(len(new_rules))\n",
    "        \n",
    "        rules_ = np.empty(shape=[len(new_rules), 1],dtype='object')\n",
    "        rules_[:,0] = new_rules\n",
    "        rules = np.concatenate((rules,rules_))\n",
    "                        \n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert prem_terms.shape[1] == yt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_degree = np.ndarray(shape=(prem_terms.shape[0],mY_.shape[1],mY_.shape[2]))\n",
    "complete_rules = np.empty(shape=[rules.shape[0], num_series],dtype='object')\n",
    "\n",
    "for i in range(mY_.shape[2]):\n",
    "    \n",
    "    num_ = np.dot(prem_terms,mY_[:,:,i])\n",
    "    \n",
    "    ones = np.ones((num_.shape[0],num_.shape[1]))\n",
    "    \n",
    "    \n",
    "    prem_den = np.sqrt(np.sum(prem_terms**2,axis=1))\n",
    "    \n",
    "    mY_den = np.sqrt(np.sum(mY_[:,:,i]**2,axis=0))\n",
    "    \n",
    "    \n",
    "    den1 = ones*prem_den[:,None]\n",
    "    den2 = (ones.T * mY_den[:,None]).T\n",
    "    \n",
    "    den_ = np.multiply(den1,den2)\n",
    "    match_degree[:,:,i] = np.divide(num_,den_)\n",
    "    \n",
    "    best_match = np.argmax(match_degree[:,:,i],axis=1)\n",
    "    \n",
    "    for k in range(rules.shape[0]):\n",
    "        one_rule = deepcopy(rules[k,0])\n",
    "        one_rule.append((i,best_match[k]))\n",
    "        complete_rules[k,i] = one_rule\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_rules.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#complete_rules[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rules_by_consequent(rules,n_serie,n_set):\n",
    "    index_ = []\n",
    "    k = 0\n",
    "    for rule in rules[:,n_serie]:\n",
    "        if rule[-1] == (n_serie,n_set):\n",
    "            index_.append(k)\n",
    "        k += 1\n",
    "    #print(index_)\n",
    "    return index_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = find_rules_by_consequent(complete_rules,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wd_ = np.zeros(shape=(complete_rules.shape[0],mY_.shape[1],mY_.shape[2]))\n",
    "\n",
    "global tryout\n",
    "tryout = 0\n",
    "def objective_function(x, mY, mX_a):\n",
    "    global tryout\n",
    "    #print(x)\n",
    "    m_diag = np.diag(x)\n",
    "    #print(x.shape)\n",
    "    #print(mY.shape)\n",
    "    #print(mX_a.shape)\n",
    "    #print(m_diag.shape)\n",
    "    a = np.sum(np.dot(m_diag,mX_a),axis=0)\n",
    "    #print(a.shape)\n",
    "    y = mY - a\n",
    "    tryout += 1\n",
    "    if (tryout%100 == 0):\n",
    "        print('Attempt #{}'.format(tryout))\n",
    "    return np.sum(np.sqrt(y**2))\n",
    "\n",
    "\n",
    "def constraint_function(x):\n",
    "    \n",
    "    return np.sum(x) - 1\n",
    "\n",
    "\n",
    "    \n",
    "isEmpty = True\n",
    "\n",
    "agg_training = np.zeros(shape=mY_.shape)\n",
    "\n",
    "if isEmpty == True:\n",
    "    for series in range(mY_.shape[2]):\n",
    "        for n_set in range(mY_.shape[1]):\n",
    "            index_consequents = np.where(mY_[:,n_set,series] > 0)\n",
    "\n",
    "            index_premises = find_rules_by_consequent(complete_rules,series,n_set)\n",
    "            if len(index_consequents) > 0: \n",
    "                if len(index_premises) > 0:\n",
    "                    filter_prem = prem_terms[index_premises,:]\n",
    "\n",
    "                    activated_prem = filter_prem[:,index_consequents[0]]\n",
    "\n",
    "                    filtered_consequents = mY_[index_consequents,n_set,series]\n",
    "                    tryout = 0\n",
    "                    print('---------------------------')\n",
    "                    print('Shape of activated prem is {}'.format(activated_prem.shape))\n",
    "                    \n",
    "                    cons = [{\"type\": \"eq\", \"fun\": constraint_function}]\n",
    "\n",
    "                    bnds = [(0,1) for i in range(filter_prem.shape[0])]\n",
    "\n",
    "                    res = minimize(objective_function,np.ones((activated_prem.shape[0])),args = (filtered_consequents,activated_prem), bounds = bnds, constraints = cons, tol = 1e-2)\n",
    "                    print('Shape of initial guess is {}'.format(np.ones((activated_prem.shape[0])).shape))\n",
    "                    print('Shape of res is {}'.format(res.x.shape))\n",
    "                    print('Non-zeros weights = {}'.format(np.sum(np.where(res.x>0))))\n",
    "                    \n",
    "                    weighted_rules = activated_prem * res.x[:,None]\n",
    "                    \n",
    "                    aggr_rules = weighted_rules.max(axis=0)\n",
    "                    \n",
    "                    agg_training[index_consequents,n_set,series] = aggr_rules\n",
    "                    \n",
    "                    wd_[index_premises,n_set,series] = res.x\n",
    "    isEmpty == False\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defuzzification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Definition of support of every out.\n",
    "\n",
    "def defuzz_cog(agg_training,mf_params_,num_series,show=False):\n",
    "    y_predict_ = np.zeros((agg_training.shape[0],num_series))\n",
    "    for i in range(num_series):\n",
    "\n",
    "        a = int(mf_params_[-1,i] - mf_params_[0,i])\n",
    "        support_discourse = np.linspace(mf_params_[0,i],mf_params_[-1,i],num=a)\n",
    "        all_values = np.zeros((support_discourse.shape[0],mf_params_.shape[0]))\n",
    "\n",
    "        for j in range(mf_params_.shape[0]):\n",
    "            if j == 0:\n",
    "                k = 0\n",
    "                for val in support_discourse:\n",
    "                    all_values[k,j] = trapmf(val,-1000*abs(mf_params_[j,i]),-1000*abs(mf_params_[j,i]),mf_params_[j,i],mf_params_[j+1,i])\n",
    "                    k += 1\n",
    "                #print(all_values[:,j,i])\n",
    "\n",
    "            elif j < mf_params_.shape[0] - 1:\n",
    "                k = 0\n",
    "                for val in support_discourse:\n",
    "                    all_values[k,j] = trimf(val,mf_params_[j-1,i],mf_params_[j,i],mf_params_[j+1,i])\n",
    "                    k += 1\n",
    "\n",
    "            else:\n",
    "                k = 0\n",
    "                for val in support_discourse:\n",
    "                    all_values[k,j] = trapmf(val,mf_params_[j-1,i],mf_params_[j,i],1000*abs(mf_params_[j,i]),1000*abs(mf_params_[j,i]))\n",
    "                    k += 1\n",
    "\n",
    "        for p in range(agg_training.shape[0]):\n",
    "            p_in = np.ones(shape=all_values.shape) * agg_training[p,:,i]  \n",
    "\n",
    "            out = np.minimum(all_values,p_in)\n",
    "            outResponse = np.maximum.reduce(out,axis=1)\n",
    "\n",
    "            y_predict = sum(np.multiply(support_discourse,outResponse))/(sum(outResponse))\n",
    "\n",
    "            y_predict_[p,i] = y_predict\n",
    "            \n",
    "        if show:\n",
    "            plt.figure(figsize=(16,9))\n",
    "            for i in range(all_values.shape[1]):\n",
    "                plt.plot(support_discourse,out)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "    return y_predict_\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(A,F):\n",
    "    return np.mean(np.abs(np.divide(A-F,A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_ = defuzz_cog(agg_training,mf_params_,num_series,show=False)\n",
    "\n",
    "for i in range(num_series):\n",
    "    idx = np.where(np.isnan(y_predict_[:,i]))\n",
    "\n",
    "    if len(idx) > 0:\n",
    "        y_predict_[idx,i] = 0\n",
    "        \n",
    "        print('There are {} NaN in prediction'.format(len(idx[0])))\n",
    "    print('MAE score for serie {} is {}'.format(i+1,mean_absolute_error(yt[:,i], y_predict_[:,i])))\n",
    "    print('RMSE for serie {} is {}'.format(i+1,sqrt(mean_squared_error(yt[:,i], y_predict_[:,i]))))\n",
    "    print('SMAPE for serie {} is {}'.format(i+1,smape(yt[:,i], y_predict_[:,i])))\n",
    "    print('MAPE for serie {} is {}'.format(i+1,mape(yt[:,i], y_predict_[:,i])))\n",
    "    print('R2 score for serie {} is {}'.format(i+1,r2_score(yt[:,i], y_predict_[:,i])))\n",
    "    print('----------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_series):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Serie {}'.format(i+1))\n",
    "    plt.plot(y_predict_[:,i],color='blue')\n",
    "    plt.plot(yt[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if diff_series:\n",
    "    y__ = y_predict_ + data[lag:in_sample.shape[0]-1,:]\n",
    "    for i in range(num_series):\n",
    "\n",
    "        compare_series = data[lag:in_sample.shape[0]-1,i]\n",
    "        plt.figure(figsize=(10,6))\n",
    "\n",
    "        plt.title('Serie {}'.format(i+1))\n",
    "\n",
    "        plt.plot(y__[:,i],color='blue')\n",
    "\n",
    "        plt.plot(data[lag:in_sample.shape[0]-1,i],color='red')\n",
    "\n",
    "        plt.legend(['Predicted','Target'])\n",
    "\n",
    "        print('MAE score for serie {} is {}'.format(i+1,mean_absolute_error(compare_series, y__[:,i])))\n",
    "        print('RMSE for serie {} is {}'.format(i+1,sqrt(mean_squared_error(compare_series, y__[:,i]))))\n",
    "        print('SMAPE for serie {} is {}'.format(i+1,smape(compare_series, y__[:,i])))\n",
    "        print('MAPE for serie {} is {}'.format(i+1,mape(compare_series, y__[:,i])))\n",
    "        print('R2 score for serie {} is {}'.format(i+1,r2_score(compare_series, y__[:,i])))\n",
    "        print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to remove diff from time series"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "yt_without_diff = np.zeros((y_predict_.shape))\n",
    "yt_without_diff[0,:] = in_sample[lag,:] + y_predict_[0,:]\n",
    "\n",
    "for i in range(1,y_predict_.shape[0]):\n",
    "    yt_without_diff[i,:] = yt_without_diff[i-1,:] + y_predict_[i,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(num_series):\n",
    "    print('RMSE for serie {} is {}'.format(i+1,sqrt(mean_squared_error(yt[:,i], yt_without_diff[:,i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(num_series):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Serie {}'.format(i+1))\n",
    "    plt.plot(yt_without_diff[:,i],color='blue')\n",
    "    plt.plot(in_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rules_by_antecedent(rules,val):\n",
    "    index_ = []\n",
    "    k = 0\n",
    "    for rule in rules:\n",
    "        #print(rule)\n",
    "        if check_if_inside(val,rule[0]):\n",
    "            index_.append(k)\n",
    "        k += 1\n",
    "    #print(index_)\n",
    "    return index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(rule,antecedents_activated):\n",
    "    for term in rule[0]:\n",
    "        \n",
    "        if term in antecedents_activated:\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blabla(a,b):\n",
    "    for antec in a:\n",
    "        print(antec)\n",
    "        if not (antec in b):\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prem_term(rule,muX):\n",
    "    prem_concat = []\n",
    "    for term in rule:\n",
    "        #print(term)\n",
    "        prem_concat.append(muX[0,term[1],term[0]])\n",
    "    return tnorm_product(prem_concat)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrumação dos dados para previsão.\n",
    "yp_totest = yp_lagged[yp_lagged.shape[0]-1:yp_lagged.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_totest = np.zeros((h_prev,num_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for h_p in range(h_prev):\n",
    "    mX_values_in = np.zeros((1,mf_params_.shape[0],yp_totest.shape[1]))\n",
    "    antecedents_activated = []\n",
    "    for i in range(num_series):\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "\n",
    "            mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params)\n",
    "            mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "            idx_nonzero = np.where(mX[0,:] > 0)\n",
    "            idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "            for k in range(idx_nonzero.shape[0]):\n",
    "                antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "            \n",
    "\n",
    "    check_idx = 0\n",
    "    rules_idx = []\n",
    "    prem_terms_test = np.zeros((rules.shape[0],1))\n",
    "\n",
    "    for n_rule in rules:\n",
    "        #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "        if test(n_rule,antecedents_activated):\n",
    "            rules_idx.append(check_idx)\n",
    "        check_idx += 1\n",
    "        \n",
    "    prem_activated = np.zeros((rules.shape[0],))\n",
    "    for i in rules_idx:\n",
    "        prem_activated[i,] = prem_term(rules[i,0],mX_values_in)\n",
    "    \n",
    "    agg_test = np.zeros((wd_.shape))\n",
    "    for i in range(num_series):\n",
    "        for j in rules_idx:\n",
    "            rule = complete_rules[j,i]\n",
    "            consequent = rule[-1]\n",
    "            agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "            \n",
    "            \n",
    "    weight_agg = np.multiply(agg_test,wd_)\n",
    "    weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "    for i in range(weight_.shape[1]):\n",
    "        weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "    w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "    \n",
    "    \n",
    "    y_pred = defuzz_cog(w_todefuzz,mf_params_,num_series,show=True)\n",
    "    \n",
    "    yt_totest[h_p,:] = y_pred\n",
    "    \n",
    "    yp_totest = np.roll(yp_totest,1)\n",
    "    \n",
    "    for i in range(num_series):\n",
    "        yp_totest[0,i*lag] = y_pred[0][i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_series):\n",
    "    print('RMSE for serie {} is {}'.format(i+1,sqrt(mean_squared_error(yt_totest[:,i], out_sample[:,i]))))\n",
    "    print('SMAPE for serie {} is {}'.format(i+1,smape(out_sample[:,i],yt_totest[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_series):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Serie {}'.format(i+1))\n",
    "    plt.plot(yt_totest[:,i],color='blue')\n",
    "    plt.plot(out_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "check_idx = 0\n",
    "rules_idx = []\n",
    "prem_terms_test = np.zeros((rules.shape[0],1))\n",
    "\n",
    "for a in rules:\n",
    "    #print('Rule {} is {}'.format(check_idx,test(a,antecedents_activated)))\n",
    "    if test(a,antecedents_activated):\n",
    "        rules_idx.append(check_idx)\n",
    "    check_idx += 1\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prem_activated = np.zeros((rules.shape[0],))\n",
    "for i in rules_idx:\n",
    "    prem_activated[i,] = prem_term(rules[i,0],mX_values_in)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "agg_test = np.zeros((wd_.shape))\n",
    "for i in range(num_series):\n",
    "    for j in rules_idx:\n",
    "        rule = complete_rules[j,i]\n",
    "        consequent = rule[-1]\n",
    "        agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_agg = np.multiply(agg_test,wd_)\n",
    "weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "for i in range(weight_.shape[1]):\n",
    "    weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = defuzz_cog(w_todefuzz,mf_params_,num_series)\n",
    "yt_totest[0,:] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yt_totest[0,:] = y_pred"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "yp1_totest = np.roll(yp_totest,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_without_diff = np.zeros((yt_totest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_without_diff[0,:] = in_sample[in_sample.shape[0]-1,:] + yt_totest[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,h_prev):\n",
    "    yt_without_diff[i,:] = yt_without_diff[i-1,:] + yt_totest[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_series):\n",
    "    print('RMSE for serie {} is {}'.format(i+1,sqrt(mean_squared_error(yt_without_diff[:,i], out_sample[:,i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_without_diff = np.zeros((yt_totest.shape))\n",
    "\n",
    "out_without_diff[0,:] = out_sample[0,:] - in_sample[in_sample.shape[0]-1,:]\n",
    "\n",
    "for i in range(1,h_prev):\n",
    "    out_without_diff[i,:] = out_sample[i,:] - out_sample[i-1,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(num_series):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Serie {}'.format(i+1))\n",
    "    plt.plot(yt_without_diff[:,i],color='blue')\n",
    "    plt.plot(out_without_diff[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(wd_ > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
